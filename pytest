Source : https://www.tutorialspoint.com/pytest/index.htm

Running pytest without mentioning a filename will run all files of format test_*.py or *_test.py in the current directory and subdirectories. Pytest automatically identifies those files as test files. We can make pytest run other filenames by explicitly mentioning them.

Pytest requires the test function names to start with test. Function names which are not of format test* are not considered as test functions by pytest. We cannot explicitly make pytest consider any function not starting with test as a test function.


import math

def test_sqrt():
   num = 25
   assert math.sqrt(num) == 5

def testsquare():
   num = 7
   assert 7*7 == 40

def tesequality():
   assert 10 == 11
   
   
> pytest  -v

To execute the tests from a specific file, use the following syntax −

pytest <filename> -v
Now, run the following command −

pytest test_compare.py -v

Pytest provides two ways to run the subset of the test suite.

Select tests to run based on substring matching of test names.
Select tests groups to run based on the markers applied.


To execute the tests containing a string in its name we can use the following syntax −

pytest -k <substring> -v
-k <substring> represents the substring to search for in the test names.

pytest -k great -v

========
 users can create their own marker names. Markers are applied on the tests using the syntax given below −

@pytest.mark.<markername>
To use markers, we have to import pytest module in the test file. We can define our own marker names to the tests and run the tests having those marker names.

To run the marked tests, we can use the following syntax −

pytest -m <markername> -v

test_compare.py
import pytest
@pytest.mark.great
def test_greater():
   num = 100
   assert num > 100

@pytest.mark.great
def test_greater_equal():
   num = 100
   assert num >= 100

@pytest.mark.others
def test_less():
   num = 100
   assert num < 200
test_square.py
import pytest
import math

@pytest.mark.square
def test_sqrt():
   num = 25
   assert math.sqrt(num) == 5

@pytest.mark.square
def testsquare():
   num = 7
   assert 7*7 == 40

@pytest.mark.others
   def test_equality():
   assert 10 == 11
Now to run the tests marked as others, run the following command −

pytest -m others -v

==============
fixtures

Fixtures are functions, which will run before each test function to which it is applied. Fixtures are used to feed some data to the tests such as database connections, URLs to test and some sort of input data. Therefore, instead of running the same code for every test, we can attach fixture function to the tests and it will run and return the data to the test before executing each test

import pytest

@pytest.fixture
def input_value():
   input = 39
   return input

def test_divisible_by_3(input_value):
   assert input_value % 3 == 0

def test_divisible_by_6(input_value):
   assert input_value % 6 == 0
   
   
 Execute the test using the following command −

pytest -k divisible -v

============
We can define the fixture functions in this file to make them accessible across multiple test files.

Create a new file conftest.py and add the below code into it −

import pytest

@pytest.fixture
def input_value():
   input = 39
   return input
   
================
parametrizing tests

Parameterizing of a test is done to run the test against multiple sets of inputs. We can do this by using the following marker −

@pytest.mark.parametrize
Copy the below code into a file called test_multiplication.py −

import pytest

@pytest.mark.parametrize("num, output",[(1,11),(2,22),(3,35),(4,44)])
def test_multiplication_11(num, output):
   assert 11*num == output

================
xfail and skip

Now, consider the below situations −

A test is not relevant for some time due to some reasons.
A new feature is being implemented and we already added a test for that feature.
In these situations, we have the option to xfail the test or skip the tests.

Pytest will execute the xfailed test, but it will not be considered as part failed or passed tests. Details of these tests will not be printed even if the test fails (remember pytest usually prints the failed test details). We can xfail tests using the following marker −

@pytest.mark.xfail
Skipping a test means that the test will not be executed. We can skip tests using the following marker −

@pytest.mark.skip


import pytest
@pytest.mark.xfail
@pytest.mark.great
def test_greater():
   num = 100
   assert num > 100

@pytest.mark.xfail
@pytest.mark.great
def test_greater_equal():
   num = 100
   assert num >= 100

@pytest.mark.skip
@pytest.mark.others
def test_less():
   num = 100
   assert num < 200
Execute the test using the following command −

pytest test_compare.py -v

test_compare.py::test_greater xfail
test_compare.py::test_greater_equal XPASS
test_compare.py::test_less SKIPPED
============================ 1 skipped, 1 xfailed, 1 xpassed in 0.06 seconds
============================
Stop Test Suite after N Test Failures

The syntax to stop the execution of test suite soon after n number of test fails is as follows −

pytest --maxfail = <num>


import pytest
import math

def test_sqrt_failure()
   num = 25
   assert math.sqrt(num) == 6

def test_square_failure():
   num = 7
   assert 7*7 == 40

def test_equality_failure():
   assert 10 == 11
   
pytest test_failure.py -v --maxfail = 1

====================
By default, pytest runs tests in sequential order. In a real scenario, a test suite will have a number of test files and each file will have a bunch of tests. This will lead to a large execution time. To overcome this, pytest provides us with an option to run tests in parallel.

For this, we need to first install the pytest-xdist plugin.

Install pytest-xdist by running the following command −

pip install pytest-xdist
Now, we can run tests by using the syntax pytest -n <num>

pytest -n 3
-n <num> runs the tests by using multiple workers, here it is 3.

============================
We can generate the details of the test execution in an xml file.

pytest test_multiplication.py -v --junitxml="result.xml"

   
   
